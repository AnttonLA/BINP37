{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logbook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBv6tDYfnCMKiV91gX5Xui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnttonLA/BINP37/blob/master/logbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtYoNzSZWARW",
        "colab_type": "text"
      },
      "source": [
        "# 31 - 03 - 2020 (And before)\n",
        "\n",
        "**Aim:** Set up bioBERT in Colab. Make it work.\n",
        "\n",
        "**Result:** After some compatibility issues, bioBERT seems to be working. Fine-tunning was performed.\n",
        "\n",
        "**Next step:** Use bioBERT to make predictions with the fine-tuned model.\n",
        "\n",
        "I found a really useful comment on the tensorflow GitHub about installing an older version of Cuda, which is necessary for BioBERT to run: https://github.com/tensorflow/tensorflow/issues/15604#issuecomment-368286864"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glaNtIkpIFug",
        "colab_type": "text"
      },
      "source": [
        "# 02 - 04 - 2020\n",
        "\n",
        "**Aim:** Confirm that BioBERT performs prediction not only for the given datasets, but for custom datasets as well.\n",
        "\n",
        "**Result:** After a lot of struggling, we see that it can indeed use our data, but it needs some workarounds and the data needs to be *very* specifically formated.\n",
        "\n",
        "**Next step:** Format our data in the desired way so that we can perfrom prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhHWMTS0ZQvv",
        "colab_type": "text"
      },
      "source": [
        "#05 - 04 - 2020\n",
        "**Aim:** Get a 'test.tsv' file that is compatible with bioBERTs prediciton.\n",
        "\n",
        "**Result:** Managed to figure out the exact format of the dataset required for bioBERT to work properly. I wrote some preliminary scripts that make text into that format. I was able to get a rough version of the full pipeline, obtaining the Named Entities of the text.\n",
        "\n",
        "**Next step:** Perfect the pipeline. Specifically, improve on the scripts that format the data in the correct way to be used in BioBERT.\n",
        "\n",
        "On paralell with this, I completed a \"guide\" on how to set up BioBERT in Colab, as I thought it'd be usefull to others (and me) in the future. It can be found here: https://github.com/AnttonLA/BINP37/blob/master/bioBERT.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaOs5oadoqMw",
        "colab_type": "text"
      },
      "source": [
        "#07 - 04 - 2020\n",
        "\n",
        "**Aim:** Transform the whole 100 paper subset to the appropriate tsv format in order for it to work in BioBERT\n",
        "\n",
        "**Result:** I fixed the script that creates the tsv. Right now it creates a working file from a single paper, and the prediction works fine in that paper.\n",
        "\n",
        "**Next Step:** Generalize the script so that it works in all 100 papers. Get the output file and transform the output to PubAnnotation format.\n",
        "\n",
        "I decided to use some extra time to watch some YouTube videos and do some reading (re-read the main paper and part of the BERN paper). It was very much worth it: I learned a lot in the last couple of days about BERT, BioBERT and NLP in general and that helped with the coding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fm21g0i6JAR",
        "colab_type": "text"
      },
      "source": [
        "# 08 - 05 - 2020\n",
        "\n",
        "**Aim:** Create custom script that will generate a 'test.tsv' file of the appropriate format from the 100 paper subset, so that it can be used in BioBERT. Do prediction in BioBERT with it.\n",
        "\n",
        "**Result:** I finished the pipeline to generate '.tsv' files to use for prediction from the JSON files. The scripts are here: https://github.com/AnttonLA/BINP37/tree/master/dataset_generation\n",
        "Prediction with the 100 papers accomplished. Started working on a script that will transform the output file to PubAnnotation format, which proved trickier than expected.\n",
        "\n",
        "**Next Step:** Finish that last script, upload the next JSON file.\n",
        "\n",
        "The methods used by the BioBERT team for data pre-processing were not made public. I managed to approximate the pre-processing taking inspiration from https://github.com/spyysalo/standoff2conll/blob/master/common.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6jMNgpGpJXx",
        "colab_type": "text"
      },
      "source": [
        "# 13 - 05 - 2020\n",
        "\n",
        "**Aim:** Reproduce results from the BioBERT paper for three of the \"default\" datasets.\n",
        "\n",
        "**Result:** I got Precision, Recall and F-Score for three models: *NCBI-Disease*, *BC5CDR-Chemicals* and *JNLPBA*. The results are close to those shown in the BioBERT paper. I stored the fine-tuned models in my Drive since the process is quite time consuming. This way I can just load them from there instead of doing it all over again.\n",
        "\n",
        "**Next Step:** Finish the upload to PubAnnotation.\n",
        "\n",
        "Also in the #TODO list: update/slightly improve on the BioBERT guide, and improve on the documentation in several files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVkZGzq2U6uM",
        "colab_type": "text"
      },
      "source": [
        "#15 - 05 - 2020\n",
        "\n",
        "**Aim:** Finish the script that converts the output to PubAnnotation\n",
        "\n",
        "**Result:** It could be more solid, but the the script it done and seems to work fine.\n",
        "\n",
        "**Next Step:** Obtain final PubAnnotation files of the 100 paper subset\n",
        "\n",
        "Also, improve on guide and documentation, as well as project architecture. It's time for a little file cleanup! \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWx5ALXCU6xo",
        "colab_type": "text"
      },
      "source": [
        "# 16 - 05 - 2020\n",
        "\n",
        "**Aim:** Generate the final JSON files that correspond to the 100 paper subset.\n",
        "\n",
        "**Result:** Once again, a slight rework of the formatting scripts was required, but it worked out in the end. I created all the JSON files.\n",
        "The final scripts (as well as the compressed files) can be found here:\n",
        "\n",
        " https://github.com/AnttonLA/BINP37/tree/master/dataset_generation\n",
        "\n",
        " https://github.com/AnttonLA/BINP37/tree/master/output_generation\n",
        "\n",
        "\n",
        "**Next Step:** Cleanup + start looking into setting BioBERT up in Lunarc so that I can train a proper model to check the gold standard dataset with. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAr2qUSMvYH6",
        "colab_type": "text"
      },
      "source": [
        "#17 - 05 - 2020\n",
        "\n",
        "**Aim:** Learn how to access and use Lunarc. \n",
        "\n",
        "BONUS: figure out why the PubAnnotation format JSON files have the wrong text assigned.\n",
        "\n",
        "**Results:** I read the guides provided by SNIC. However a lot of things are still unclear to me.\n",
        "\n",
        "I discovered that when extracting the text from the files of the 100 paper dataset I was skipping over parts of the abstract in the cases where the abstract was composed by multiple paragraphs. Not sure if this was the cause of the miss-alignment of text/name in the final output.\n",
        "\n",
        "**Next Step:** Top priority is to keep investigating the miss-alingment and fix it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-FCNuVlvYby",
        "colab_type": "text"
      },
      "source": [
        "#20 - 05 - 20\n",
        "\n",
        "**Aim:** Fix the output files.\n",
        "\n",
        "**Result:** Issue fixed. It was caused by the fact that a few files from the database lacked titles or had multi-paragraph abstracts. \n",
        "\n",
        "**Next Step:** Back to learning about Lunarc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID9HFDriZPOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E9EUc55ICbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}